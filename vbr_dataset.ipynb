{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1204e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vbrInterpolatedDataset from scene:  ciampino_train0\n",
      "Images loaded from:  /datasets/vbr_slam/ciampino/ciampino_train0_kitti/camera_left/data\n",
      "Ground Truth Poses:  /datasets/vbr_slam/ciampino/ciampino_train0/ciampino_train0_gt.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pyproj import Transformer\n",
    "from my_vbr_utils.vbr_dataset import vbrInterpolatedDataset, get_paths_from_scene, load_calibration\n",
    "from my_vbr_utils.utilities import load_scene_correspondences\n",
    "\n",
    "\n",
    "location = 'ciampino_train0'\n",
    "dataset_root = '/datasets/vbr_slam'\n",
    "\n",
    "# Load dataset and calibration\n",
    "vbr_scene = vbrInterpolatedDataset(dataset_root, location)\n",
    "calib_path=get_paths_from_scene(dataset_root, location)[-1]\n",
    "calib = load_calibration(calib_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dffd7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vbr_scene_traj = vbr_scene.get_local_trajectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14acebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# n = 2000 #step \n",
    "\n",
    "# x1, y1 = vbr_scene_traj[:, 0], vbr_scene_traj[:, 1]\n",
    "# indices = np.arange(0, len(x1), n)\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.plot(x1, y1, 'b-', alpha=0.5, label='')\n",
    "\n",
    "# plt.scatter(x1[0], y1[0], color='red', marker='x', s=60, label='Start')\n",
    "# plt.scatter(x1[-1], y1[-1], color='green', marker='x', s=60, label='End')\n",
    "# plt.scatter(x1[indices[1:-1]], y1[indices[1:-1]], color='blue', marker='o', s=60, label='')\n",
    "\n",
    "# # Annotate each anchor with its index (excluding first and last)\n",
    "# for idx in indices[1:-1]:\n",
    "#     plt.text(x1[idx] + 2, y1[idx] + 2, str(idx), color='blue', fontsize=8,  # <-- increased fontsize here\n",
    "#              ha='left', va='bottom',\n",
    "#              bbox=dict(facecolor='white', edgecolor='none', alpha=0.7, pad=0.5))\n",
    "\n",
    "# plt.xlabel('X (m)', fontsize=14)\n",
    "# plt.ylabel('Y (m)', fontsize=14)\n",
    "# plt.legend(fontsize=12)\n",
    "# plt.grid(True, linestyle='--', alpha=0.5)\n",
    "# plt.title(f\"{location} in Local Frame\", fontsize=16)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a43c2bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1145): [[3026, 3421]], (1145, 1496): [[3421, 3772], [16708, 17244]], (1496, 2456): [[29980, 30849]], (3773, 4594): [[17246, 18245]], (4600, 5390): [[6000, 7300], [18300, 19000]], (13236, 14000): [[11470, 12115]], (14396, 15046): [[24900, 26000]], (15113, 16612): [[21360, 21900], [26986, 27735]]}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "json_path = f\"/home/bjangley/VPR/mast3r-v2/my_vbr_utils/vbr_sequences/{location}.json\"\n",
    "def load_anchor_query_dict(json_file_path):\n",
    "    \"\"\"\n",
    "    Load the anchor-query dictionary from a JSON file.\n",
    "    \"\"\"\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        loaded_dict = json.load(f)\n",
    "\n",
    "    # Convert string keys back to tuples\n",
    "    anchor_query_dict = {tuple(map(int, key.strip(\"()\").split(\",\"))): value for key, value in loaded_dict.items()}\n",
    "    return anchor_query_dict\n",
    "anchor_query_dict=load_anchor_query_dict(json_path)\n",
    "print(anchor_query_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fea30bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import ipywidgets as widgets\n",
    "\n",
    "\n",
    "# def plot_subplots_with_start_stop(anchor_range):\n",
    "#     query_ranges = anchor_query_dict.get(anchor_range)\n",
    "#     if query_ranges is None:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 4))\n",
    "#         ax.text(0.5, 0.5, f\"No query ranges found for anchor range {anchor_range}.\",\n",
    "#                 ha='center', va='center')\n",
    "#         ax.axis('off')\n",
    "#         return fig\n",
    "\n",
    "#     n_total = 1 + len(query_ranges)\n",
    "#     n_cols = 3\n",
    "#     n_rows = int(np.ceil(n_total / n_cols))\n",
    "#     fig, axs = plt.subplots(n_rows, n_cols, figsize=(7 * n_cols, 5 * n_rows), squeeze=False)\n",
    "#     axs = axs.flatten()\n",
    "\n",
    "#     seg = vbr_scene_traj\n",
    "#     n = 50\n",
    "#     # 1) Plot the anchor\n",
    "#     anchor_seq = vbr_scene_traj[anchor_range[0]:anchor_range[1]]\n",
    "#     axs[0].plot(seg[:,0], seg[:,1], color='red', alpha=0.3, label=\"Full Trajectory\")\n",
    "#     axs[0].plot(anchor_seq[:,0], anchor_seq[:,1], 'g-', linewidth=2.5, label=f\"Anchor {anchor_range}\")\n",
    "#     # Start marker\n",
    "#     axs[0].plot(anchor_seq[0,0], anchor_seq[0,1], 'o', color='green', markersize=12, label='Start')\n",
    "#     # axs[0].text(anchor_seq[0,0], anchor_seq[0,1]-n, f\"Start: {anchor_range[0]}\", fontsize=10,\n",
    "#     #             color='green', va='bottom', ha='right', bbox=dict(facecolor='white', alpha=0.7))\n",
    "#     # End marker\n",
    "#     axs[0].plot(anchor_seq[-1,0], anchor_seq[-1,1], 'X', color='darkgreen', markersize=12, label='End')\n",
    "#     # axs[0].text(anchor_seq[-1,0], anchor_seq[-1,1]-n, f\"End: {anchor_range[1]}\", fontsize=10,\n",
    "#     #             color='darkgreen', va='top', ha='left', bbox=dict(facecolor='white', alpha=0.7))\n",
    "#     axs[0].set_title(f\"Anchor {anchor_range}\")\n",
    "#     axs[0].legend()\n",
    "#     axs[0].grid(True, linestyle='--')\n",
    "\n",
    "#     # 2) Plot each query range\n",
    "#     for i, (qs, qe) in enumerate(query_ranges, start=1):\n",
    "#         query_seq = vbr_scene_traj[qs:qe]\n",
    "#         axs[i].plot(seg[:,0], seg[:,1], color='red', alpha=0.3, label=\"Full Trajectory\")\n",
    "#         axs[i].plot(query_seq[:,0], query_seq[:,1], 'blue', linewidth=2, label=f\"Query {i}: {qs}-{qe}\")\n",
    "#         # Start marker\n",
    "#         axs[i].plot(query_seq[0,0], query_seq[0,1], 'o', color='blue', markersize=12, label='Start')\n",
    "#         # axs[i].text(query_seq[0,0], query_seq[0,1]-n, f\"Start: {qs}\", fontsize=10,\n",
    "#         #             color='purple', va='bottom', ha='right', bbox=dict(facecolor='white', alpha=0.7))\n",
    "#         # End marker\n",
    "#         axs[i].plot(query_seq[-1,0], query_seq[-1,1], 'X', color='blue', markersize=12, label='End')\n",
    "#         # axs[i].text(query_seq[-1,0], query_seq[-1,1]-n, f\"End: {qe}\", fontsize=10,\n",
    "#         #             color='indigo', va='top', ha='left', bbox=dict(facecolor='white', alpha=0.7))\n",
    "#         axs[i].set_title(f\"Query {i}: {qs}-{qe}\")\n",
    "#         axs[i].legend()\n",
    "#         axs[i].grid(True, linestyle='--')\n",
    "\n",
    "#     # Hide unused subplots\n",
    "#     for i in range(n_total, len(axs)):\n",
    "#         axs[i].axis('off')\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     return fig\n",
    "\n",
    "\n",
    "# anchor_ranges = list(anchor_query_dict.keys())\n",
    "# range_names = [str(r) for r in anchor_ranges]\n",
    "# range_selector = widgets.SelectionSlider(\n",
    "#     options=range_names,\n",
    "#     description='Anchor:',\n",
    "#     continuous_update=False\n",
    "# )\n",
    "\n",
    "# def update_plot(anchor_range_str):\n",
    "#     anchor_range = eval(anchor_range_str)\n",
    "#     plt.close('all')\n",
    "#     return plot_subplots_with_start_stop(anchor_range)\n",
    "\n",
    "# widget = widgets.interactive(update_plot, anchor_range_str=range_selector)\n",
    "# display(widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90806fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of query sequences after subsampling with step size 20: 412\n",
      "Total number of anchor sequences after subsampling with anchor step size 10: 701\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json_path = \"/home/bjangley/VPR/mast3r-v2/my_vbr_utils/vbr_sequences/ciampino_train0.json\"\n",
    "def load_anchor_query_dict(json_file_path):\n",
    "    \"\"\"\n",
    "    Load the anchor-query dictionary from a JSON file.\n",
    "    \"\"\"\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        loaded_dict = json.load(f)\n",
    "\n",
    "    # Convert string keys back to tuples\n",
    "    anchor_query_dict = {tuple(map(int, key.strip(\"()\").split(\",\"))): value for key, value in loaded_dict.items()}\n",
    "    return anchor_query_dict\n",
    "def calculate_total_queries(anchor_query_dict, step_size):\n",
    "    \"\"\"\n",
    "    Calculates the total number of query sequences after subsampling with a given step size.\n",
    "\n",
    "    Args:\n",
    "        anchor_query_dict (dict): A dictionary where keys are anchor ranges (tuples) and\n",
    "                                   values are lists of query ranges (lists of tuples).\n",
    "        step_size (int): The step size for subsampling the query ranges.\n",
    "\n",
    "    Returns:\n",
    "        int: The total number of query sequences after subsampling.\n",
    "    \"\"\"\n",
    "    total_queries = 0\n",
    "    for anchor_range, query_ranges in anchor_query_dict.items():\n",
    "        for query_range in query_ranges:\n",
    "            start, end = query_range\n",
    "            # Calculate the number of subsampled queries for this range\n",
    "            num_queries = (end - start + step_size - 1) // step_size  # Ceiling division\n",
    "            total_queries += num_queries\n",
    "    return total_queries\n",
    "\n",
    "def calculate_total_anchors(anchor_query_dict, anchor_step_size):\n",
    "    \"\"\"\n",
    "    Calculates the total number of anchor sequences after subsampling with a given step size.\n",
    "\n",
    "    Args:\n",
    "        anchor_query_dict (dict): A dictionary where keys are anchor ranges (tuples) and\n",
    "                                   values are lists of query ranges (lists of tuples).\n",
    "        anchor_step_size (int): The step size for subsampling the anchor ranges.\n",
    "\n",
    "    Returns:\n",
    "        int: The total number of anchor sequences after subsampling.\n",
    "    \"\"\"\n",
    "    total_anchors = 0\n",
    "    for anchor_range, query_ranges in anchor_query_dict.items():\n",
    "        start, end = anchor_range\n",
    "        num_anchors = (end - start + anchor_step_size - 1) // anchor_step_size\n",
    "        total_anchors += num_anchors\n",
    "    return total_anchors\n",
    "\n",
    "# Example usage:\n",
    "step_size =20  \n",
    "anchor_step_size = 10\n",
    "anchor_query_dict=load_anchor_query_dict(json_path)\n",
    "total_queries = calculate_total_queries(anchor_query_dict, step_size)\n",
    "print(f\"Total number of query sequences after subsampling with step size {step_size}: {total_queries}\")\n",
    "\n",
    "total_anchors = calculate_total_anchors(anchor_query_dict, anchor_step_size)\n",
    "print(f\"Total number of anchor sequences after subsampling with anchor step size {anchor_step_size}: {total_anchors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf9b0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs with inliers > 200: 767\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "csv_file = \"/home/bjangley/VPR/mast3r-v2/pairs_mining/spagna_train0/spagna_matches_inliers_fm_top3_anchors_per_query.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Filter the DataFrame to include only pairs with num_inliers > 200\n",
    "filtered_df = df[df['num_inliers'] > 200]\n",
    "\n",
    "# Count the number of rows in the filtered DataFrame\n",
    "num_pairs = len(filtered_df)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of pairs with inliers > 200: {num_pairs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aafbb5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs with inliers > 200: 2485\n",
      "Number of unique anchors in the filtered dataset: 174\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "csv_file = \"/home/bjangley/VPR/mast3r-v2/pairs_mining/spagna_train0/spagna_matches_inliers_fm_top10_anchors_per_query.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Filter the DataFrame to include only pairs with num_inliers > 200\n",
    "filtered_df = df[df['num_inliers'] > 200]\n",
    "\n",
    "# Calculate the number of unique anchors in the filtered DataFrame\n",
    "num_unique_anchors = filtered_df['anchor_idx'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of pairs with inliers > 200: {len(filtered_df)}\")\n",
    "print(f\"Number of unique anchors in the filtered dataset: {num_unique_anchors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "943b5cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs:\n",
      "  Train: 1739\n",
      "  Test: 374\n",
      "  Validation: 372\n",
      "\n",
      "Number of unique anchors:\n",
      "  Train: 172\n",
      "  Test: 144\n",
      "  Validation: 140\n",
      "  Total Unique Anchors: 174\n",
      "\n",
      "Intersection sizes:\n",
      "  Train and Test: 144\n",
      "  Train and Validation: 138\n",
      "  Test and Validation: 121\n",
      "  Train, Test, and Validation: 121\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_anchor_sets(train_file, test_file, val_file):\n",
    "    \"\"\"\n",
    "    Analyzes train, test, and validation sets to determine:\n",
    "    - The number of unique anchors in each set.\n",
    "    - The size of the intersection between the sets.\n",
    "    - The total number of pairs in each set.\n",
    "    - The total number of unique anchors across all sets.\n",
    "\n",
    "    Args:\n",
    "        train_file (str): Path to the training set file.\n",
    "        test_file (str): Path to the test set file.\n",
    "        val_file (str): Path to the validation set file.\n",
    "\n",
    "    Returns:\n",
    "        None. Prints the analysis results.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_anchors(file_path):\n",
    "        \"\"\"Loads anchor and query indices from a file and returns them as sets.\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=' ', header=None, names=['anchor_idx', 'query_idx'])\n",
    "            anchor_set = set(df['anchor_idx'])\n",
    "            num_pairs = len(df)\n",
    "            return anchor_set, num_pairs\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found at {file_path}\")\n",
    "            return set(), 0\n",
    "\n",
    "    # Load anchor indices and number of pairs from each file\n",
    "    train_anchors, num_train_pairs = load_anchors(train_file)\n",
    "    test_anchors, num_test_pairs = load_anchors(test_file)\n",
    "    val_anchors, num_val_pairs = load_anchors(val_file)\n",
    "\n",
    "    # Calculate the number of unique anchors in each set\n",
    "    num_train_anchors = len(train_anchors)\n",
    "    num_test_anchors = len(test_anchors)\n",
    "    num_val_anchors = len(val_anchors)\n",
    "\n",
    "    # Calculate the intersection between the sets\n",
    "    train_test_intersection = len(train_anchors.intersection(test_anchors))\n",
    "    train_val_intersection = len(train_anchors.intersection(val_anchors))\n",
    "    test_val_intersection = len(test_anchors.intersection(val_anchors))\n",
    "    all_intersection = len(train_anchors.intersection(test_anchors).intersection(val_anchors))\n",
    "\n",
    "    # Calculate the total number of unique anchors across all sets\n",
    "    all_anchors = train_anchors.union(test_anchors).union(val_anchors)\n",
    "    num_total_unique_anchors = len(all_anchors)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Number of pairs:\")\n",
    "    print(f\"  Train: {num_train_pairs}\")\n",
    "    print(f\"  Test: {num_test_pairs}\")\n",
    "    print(f\"  Validation: {num_val_pairs}\")\n",
    "\n",
    "    print(\"\\nNumber of unique anchors:\")\n",
    "    print(f\"  Train: {num_train_anchors}\")\n",
    "    print(f\"  Test: {num_test_anchors}\")\n",
    "    print(f\"  Validation: {num_val_anchors}\")\n",
    "    print(f\"  Total Unique Anchors: {num_total_unique_anchors}\")\n",
    "\n",
    "    print(\"\\nIntersection sizes:\")\n",
    "    print(f\"  Train and Test: {train_test_intersection}\")\n",
    "    print(f\"  Train and Validation: {train_val_intersection}\")\n",
    "    print(f\"  Test and Validation: {test_val_intersection}\")\n",
    "    print(f\"  Train, Test, and Validation: {all_intersection}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "train_file = \"/home/bjangley/VPR/mast3r-v2/pairs_finetuning/spagna_train0/train_pairs.txt\"  # Replace with the actual path to your train file\n",
    "test_file = \"/home/bjangley/VPR/mast3r-v2/pairs_finetuning/spagna_train0/test_pairs.txt\"  # Replace with the actual path to your test file\n",
    "val_file = \"/home/bjangley/VPR/mast3r-v2/pairs_finetuning/spagna_train0/val_pairs.txt\"  # Replace with the actual path to your validation file\n",
    "\n",
    "analyze_anchor_sets(train_file, test_file, val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a41ef941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs:\n",
      "  Train: 1739\n",
      "  Test: 374\n",
      "  Validation: 372\n",
      "\n",
      "Number of unique anchors:\n",
      "  Train: 172\n",
      "  Test: 144\n",
      "  Validation: 140\n",
      "  Total Unique Anchors: 174\n",
      "\n",
      "Number of unique queries:\n",
      "  Train: 256\n",
      "  Test: 194\n",
      "  Validation: 200\n",
      "  Total Unique Queries: 257\n",
      "\n",
      "Intersection sizes (anchor indices):\n",
      "  Train and Test: 144\n",
      "  Train and Validation: 138\n",
      "  Test and Validation: 121\n",
      "  Train, Test, and Validation: 121\n",
      "\n",
      "Intersection sizes (query indices):\n",
      "  Train and Test: 193\n",
      "  Train and Validation: 199\n",
      "  Test and Validation: 146\n",
      "  Train, Test, and Validation: 145\n",
      "\n",
      "Intersection sizes (anchor-query pairs):\n",
      "  Train and Test: 0\n",
      "  Train and Validation: 0\n",
      "  Test and Validation: 0\n",
      "  Train, Test, and Validation: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_anchor_sets(train_file, test_file, val_file):\n",
    "    \"\"\"\n",
    "    Analyzes train, test, and validation sets to determine:\n",
    "    - The number of unique anchors in each set.\n",
    "    - The number of unique queries in each set.\n",
    "    - The size of the intersection between the sets (anchor indices).\n",
    "    - The size of the intersection between the sets (query indices).\n",
    "    - The size of the intersection between the sets (anchor-query pairs).\n",
    "    - The total number of pairs in each set.\n",
    "    - The total number of unique anchors across all sets.\n",
    "    - The total number of unique queries across all sets.\n",
    "\n",
    "    Args:\n",
    "        train_file (str): Path to the training set file.\n",
    "        test_file (str): Path to the test set file.\n",
    "        val_file (str): Path to the validation set file.\n",
    "\n",
    "    Returns:\n",
    "        None. Prints the analysis results.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_pairs(file_path):\n",
    "        \"\"\"Loads anchor and query indices from a file and returns them as sets.\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=' ', header=None, names=['anchor_idx', 'query_idx'])\n",
    "            # Create a set of (anchor_idx, query_idx) tuples\n",
    "            pairs = set(zip(df['anchor_idx'], df['query_idx']))\n",
    "            anchor_set = set(df['anchor_idx'])\n",
    "            query_set = set(df['query_idx'])\n",
    "            num_pairs = len(df)\n",
    "            return anchor_set, query_set, pairs, num_pairs\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found at {file_path}\")\n",
    "            return set(), set(), set(), 0\n",
    "\n",
    "    # Load anchor and query indices and number of pairs from each file\n",
    "    train_anchors, train_queries, train_pairs, num_train_pairs = load_pairs(train_file)\n",
    "    test_anchors, test_queries, test_pairs, num_test_pairs = load_pairs(test_file)\n",
    "    val_anchors, val_queries, val_pairs, num_val_pairs = load_pairs(val_file)\n",
    "\n",
    "    # Calculate the number of unique anchors in each set\n",
    "    num_train_anchors = len(train_anchors)\n",
    "    num_test_anchors = len(test_anchors)\n",
    "    num_val_anchors = len(val_anchors)\n",
    "\n",
    "    # Calculate the number of unique queries in each set\n",
    "    num_train_queries = len(train_queries)\n",
    "    num_test_queries = len(test_queries)\n",
    "    num_val_queries = len(val_queries)\n",
    "\n",
    "    # Calculate the intersection between the sets (anchor indices)\n",
    "    train_test_intersection_anchors = len(train_anchors.intersection(test_anchors))\n",
    "    train_val_intersection_anchors = len(train_anchors.intersection(val_anchors))\n",
    "    test_val_intersection_anchors = len(test_anchors.intersection(val_anchors))\n",
    "    all_intersection_anchors = len(train_anchors.intersection(test_anchors).intersection(val_anchors))\n",
    "\n",
    "    # Calculate the intersection between the sets (query indices)\n",
    "    train_test_intersection_queries = len(train_queries.intersection(test_queries))\n",
    "    train_val_intersection_queries = len(train_queries.intersection(val_queries))\n",
    "    test_val_intersection_queries = len(test_queries.intersection(val_queries))\n",
    "    all_intersection_queries = len(train_queries.intersection(test_queries).intersection(val_queries))\n",
    "\n",
    "    # Calculate the intersection between the sets (anchor-query pairs)\n",
    "    train_test_intersection_pairs = len(train_pairs.intersection(test_pairs))\n",
    "    train_val_intersection_pairs = len(train_pairs.intersection(val_pairs))\n",
    "    test_val_intersection_pairs = len(test_pairs.intersection(val_pairs))\n",
    "    all_intersection_pairs = len(train_pairs.intersection(test_pairs).intersection(val_pairs))\n",
    "\n",
    "    # Calculate the total number of unique anchors across all sets\n",
    "    all_anchors = train_anchors.union(test_anchors).union(val_anchors)\n",
    "    num_total_unique_anchors = len(all_anchors)\n",
    "\n",
    "     # Calculate the total number of unique queries across all sets\n",
    "    all_queries = train_queries.union(test_queries).union(val_queries)\n",
    "    num_total_unique_queries = len(all_queries)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Number of pairs:\")\n",
    "    print(f\"  Train: {num_train_pairs}\")\n",
    "    print(f\"  Test: {num_test_pairs}\")\n",
    "    print(f\"  Validation: {num_val_pairs}\")\n",
    "\n",
    "    print(\"\\nNumber of unique anchors:\")\n",
    "    print(f\"  Train: {num_train_anchors}\")\n",
    "    print(f\"  Test: {num_test_anchors}\")\n",
    "    print(f\"  Validation: {num_val_anchors}\")\n",
    "    print(f\"  Total Unique Anchors: {num_total_unique_anchors}\")\n",
    "\n",
    "    print(\"\\nNumber of unique queries:\")\n",
    "    print(f\"  Train: {num_train_queries}\")\n",
    "    print(f\"  Test: {num_test_queries}\")\n",
    "    print(f\"  Validation: {num_val_queries}\")\n",
    "    print(f\"  Total Unique Queries: {num_total_unique_queries}\")\n",
    "\n",
    "    print(\"\\nIntersection sizes (anchor indices):\")\n",
    "    print(f\"  Train and Test: {train_test_intersection_anchors}\")\n",
    "    print(f\"  Train and Validation: {train_val_intersection_anchors}\")\n",
    "    print(f\"  Test and Validation: {test_val_intersection_anchors}\")\n",
    "    print(f\"  Train, Test, and Validation: {all_intersection_anchors}\")\n",
    "\n",
    "    print(\"\\nIntersection sizes (query indices):\")\n",
    "    print(f\"  Train and Test: {train_test_intersection_queries}\")\n",
    "    print(f\"  Train and Validation: {train_val_intersection_queries}\")\n",
    "    print(f\"  Test and Validation: {test_val_intersection_queries}\")\n",
    "    print(f\"  Train, Test, and Validation: {all_intersection_queries}\")\n",
    "\n",
    "    print(\"\\nIntersection sizes (anchor-query pairs):\")\n",
    "    print(f\"  Train and Test: {train_test_intersection_pairs}\")\n",
    "    print(f\"  Train and Validation: {train_val_intersection_pairs}\")\n",
    "    print(f\"  Test and Validation: {test_val_intersection_pairs}\")\n",
    "    print(f\"  Train, Test, and Validation: {all_intersection_pairs}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "train_file = \"/home/bjangley/VPR/mast3r-v2/pairs_finetuning/spagna_train0/train_pairs.txt\"  # Replace with the actual path to your train file\n",
    "test_file = \"/home/bjangley/VPR/mast3r-v2/pairs_finetuning/spagna_train0/test_pairs.txt\"  # Replace with the actual path to your test file\n",
    "val_file = \"/home/bjangley/VPR/mast3r-v2/pairs_finetuning/spagna_train0/val_pairs.txt\"  # Replace with the actual path to your validation file\n",
    "\n",
    "analyze_anchor_sets(train_file, test_file, val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc552d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast3r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
